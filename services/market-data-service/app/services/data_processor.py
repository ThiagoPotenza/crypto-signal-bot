"""
Processador de dados de mercado OTIMIZADO
Coordena coleta de TODOS os mercados da Binance
Vers√£o 6.1 - Sistema completo e funcional com corre√ß√µes
"""

import asyncio
from typing import Dict, Any, Optional, List
from loguru import logger
from datetime import datetime, timedelta
import json
import time

from app.services.binance_client import BinanceClient
from app.services.redis_publisher import RedisPublisher
from app.services.postgres_manager import PostgresManager
from app.config import settings, get_all_symbols, MARKET_CONFIG


class MarketDataProcessor:
    """Processador principal de dados de mercado - VERS√ÉO CORRIGIDA"""
    
    def __init__(self):
        self.binance_client = BinanceClient()
        self.redis_publisher = RedisPublisher()
        self.postgres_manager = PostgresManager()
        
        # Status do sistema
        self.is_running = False
        self.start_time = None
        self.processed_messages = 0
        self.error_count = 0
        self.last_health_check = time.time()
        
        # Estat√≠sticas por mercado
        self.market_stats = {
            'spot': {'symbols': 0, 'messages': 0, 'errors': 0, 'last_update': None},
            'futures': {'symbols': 0, 'messages': 0, 'errors': 0, 'last_update': None},
            'coin_futures': {'symbols': 0, 'messages': 0, 'errors': 0, 'last_update': None},
            'options': {'symbols': 0, 'messages': 0, 'errors': 0, 'last_update': None}
        }
        
        # Cache de s√≠mbolos
        self.symbols_cache = {}
        self.last_symbol_update = None
        
        # Configura√ß√µes de performance
        self.batch_size = 1000
        self.max_queue_size = 10000
        self.health_check_interval = 30

    async def initialize(self):
        """Inicializar todos os componentes"""
        try:
            logger.info("üöÄ Inicializando Market Data Processor CORRIGIDO...")
            
            # Inicializar componentes
            await self.binance_client.initialize()
            await self.redis_publisher.initialize()
            await self.postgres_manager.initialize()
            
            # Configurar refer√™ncia circular
            self.binance_client.data_processor = self
            
            # Descobrir s√≠mbolos
            await self._discover_market_symbols()
            
            # Iniciar monitoramento
            asyncio.create_task(self._monitor_system_health())
            
            logger.success("‚úÖ Market Data Processor inicializado com sucesso")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar processor: {e}")
            raise

    async def _discover_market_symbols(self):
        """Descobrir s√≠mbolos de todos os mercados habilitados"""
        try:
            logger.info("üîé Descobrindo s√≠mbolos de todos os mercados...")
            
            # Obter s√≠mbolos otimizados - CORRE√á√ÉO AQUI!
            all_symbols = await get_all_symbols()
            
            # Verificar se retornou dados v√°lidos
            if not all_symbols or not isinstance(all_symbols, dict):
                logger.error("‚ùå Nenhum s√≠mbolo retornado ou formato inv√°lido")
                # Usar s√≠mbolos padr√£o como fallback
                all_symbols = await self._get_fallback_symbols()
            
            # Organizar por mercado
            for market, symbols in all_symbols.items():
                if not symbols:
                    logger.warning(f"‚ö†Ô∏è Nenhum s√≠mbolo para {market}")
                    continue
                    
                # Verificar se mercado est√° habilitado
                market_enabled = MARKET_CONFIG.get(market, {}).get('enabled', False)
                
                if market_enabled:
                    self.symbols_cache[market] = symbols
                    self.market_stats[market]['symbols'] = len(symbols)
                    logger.info(f"  üìä {market.upper()}: {len(symbols)} s√≠mbolos")
                else:
                    logger.info(f"  üì¥ {market.upper()}: desabilitado")
            
            total_symbols = sum(len(symbols) for symbols in self.symbols_cache.values())
            total_markets = len([m for m in self.symbols_cache.keys() if self.symbols_cache[m]])
            
            logger.success(f"üéØ Total de {total_symbols} s√≠mbolos descobertos em {total_markets} mercados")
            self.last_symbol_update = time.time()
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao descobrir s√≠mbolos: {e}")
            # Usar s√≠mbolos de fallback
            await self._setup_fallback_symbols()

    async def _get_fallback_symbols(self) -> Dict[str, List[str]]:
        """Obter s√≠mbolos de fallback em caso de erro"""
        try:
            logger.warning("‚ö†Ô∏è Usando s√≠mbolos de fallback...")
            
            # S√≠mbolos principais para teste
            fallback_symbols = {
                'spot': [
                    'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT',
                    'SOLUSDT', 'DOTUSDT', 'DOGEUSDT', 'AVAXUSDT', 'MATICUSDT',
                    'LTCUSDT', 'LINKUSDT', 'UNIUSDT', 'ATOMUSDT', 'FILUSDT'
                ],
                'futures': [
                    'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT',
                    'SOLUSDT', 'DOTUSDT', 'DOGEUSDT', 'AVAXUSDT', 'MATICUSDT'
                ]
            }
            
            logger.info(f"üì¶ Fallback: {len(fallback_symbols['spot'])} SPOT + {len(fallback_symbols['futures'])} FUTURES")
            return fallback_symbols
            
        except Exception as e:
            logger.error(f"‚ùå Erro no fallback: {e}")
            return {'spot': ['BTCUSDT'], 'futures': ['BTCUSDT']}

    async def _setup_fallback_symbols(self):
        """Configurar s√≠mbolos de fallback"""
        try:
            fallback = await self._get_fallback_symbols()
            
            for market, symbols in fallback.items():
                if MARKET_CONFIG.get(market, {}).get('enabled', False):
                    self.symbols_cache[market] = symbols
                    self.market_stats[market]['symbols'] = len(symbols)
                    logger.info(f"  üîÑ {market.upper()}: {len(symbols)} s√≠mbolos (fallback)")
            
            self.last_symbol_update = time.time()
            
        except Exception as e:
            logger.error(f"‚ùå Erro configurando fallback: {e}")

    async def start_data_collection(self):
        """Iniciar coleta de dados de todos os mercados"""
        try:
            logger.info("üé¨ Iniciando coleta de dados de TODOS os mercados...")
            self.is_running = True
            self.start_time = time.time()
            
            # Verificar se temos s√≠mbolos
            if not self.symbols_cache:
                logger.warning("‚ö†Ô∏è Nenhum s√≠mbolo encontrado para coleta")
                return
            
            # Iniciar streams WebSocket
            await self.binance_client.start_market_streams(self.symbols_cache)
            
            # Iniciar coleta hist√≥rica em background
            asyncio.create_task(self._start_historical_collection())
            
            # Iniciar limpeza peri√≥dica
            asyncio.create_task(self._periodic_cleanup())
            
            total_symbols = sum(len(symbols) for symbols in self.symbols_cache.values())
            total_markets = len(self.symbols_cache)
            
            logger.success(f"üéâ Coleta iniciada para {total_symbols} s√≠mbolos em {total_markets} mercados")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao iniciar coleta: {e}")
            raise

    async def _start_historical_collection(self):
        """Iniciar coleta de dados hist√≥ricos"""
        try:
            logger.info("üìö Iniciando coleta de dados hist√≥ricos...")
            
            # Aguardar um pouco para streams se estabilizarem
            await asyncio.sleep(30)
            
            for market, symbols in self.symbols_cache.items():
                if not symbols:
                    continue
                
                logger.info(f"üìà Coletando hist√≥rico {market.upper()}: {len(symbols)} s√≠mbolos")
                
                # Processar em lotes pequenos para n√£o sobrecarregar
                batch_size = 5
                for i in range(0, len(symbols), batch_size):
                    batch = symbols[i:i + batch_size]
                    
                    # Criar tasks para este lote
                    tasks = []
                    for symbol in batch:
                        task = asyncio.create_task(
                            self._collect_symbol_history(symbol, market)
                        )
                        tasks.append(task)
                    
                    # Aguardar lote completar
                    await asyncio.gather(*tasks, return_exceptions=True)
                    
                    # Pausa entre lotes
                    await asyncio.sleep(3)
                    
                    logger.info(f"  ‚úÖ {market.upper()}: {i + len(batch)}/{len(symbols)} s√≠mbolos processados")
                
                logger.success(f"üéâ Hist√≥rico {market.upper()} conclu√≠do")
                
        except Exception as e:
            logger.error(f"‚ùå Erro na coleta hist√≥rica: {e}")

    async def _collect_symbol_history(self, symbol: str, market: str):
        """Coletar hist√≥rico de um s√≠mbolo espec√≠fico"""
        try:
            # Intervalos para coletar
            intervals = ['1m', '5m', '1h', '1d']
            
            for interval in intervals:
                # Verificar se j√° temos dados recentes
                if await self._has_recent_data(symbol, market, interval):
                    continue
                
                # Coletar dados via API REST
                historical_data = await self._fetch_historical_klines(symbol, market, interval)
                
                if historical_data:
                    # Processar e salvar
                    for kline_data in historical_data:
                        await self.process_kline_data(kline_data)
                    
                    logger.debug(f"üìä {symbol} {interval}: {len(historical_data)} candlesticks salvos")
                
                # Pausa para respeitar rate limits
                await asyncio.sleep(0.2)
                
        except Exception as e:
            logger.error(f"‚ùå Erro coletando hist√≥rico {symbol}: {e}")

    async def _has_recent_data(self, symbol: str, market: str, interval: str) -> bool:
        """Verificar se j√° temos dados recentes para um s√≠mbolo"""
        try:
            # Por enquanto, sempre coletar dados
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erro verificando dados {symbol}: {e}")
            return False

    async def _fetch_historical_klines(self, symbol: str, market: str, interval: str) -> List[Dict]:
        """Buscar dados hist√≥ricos via API REST"""
        try:
            # Por enquanto, simular dados hist√≥ricos
            logger.debug(f"üìä Simulando hist√≥rico {symbol} {interval}")
            return []
            
        except Exception as e:
            logger.error(f"‚ùå Erro buscando hist√≥rico {symbol}: {e}")
            return []

    async def process_kline_data(self, data: Dict[str, Any]):
        """Processar dados de candlestick recebidos"""
        try:
            # Validar dados
            if not self._validate_kline_data(data):
                return
            
            # Salvar no PostgreSQL
            await self.postgres_manager.save_kline_data(data)
            
            # Publicar no Redis
            await self.redis_publisher.publish_kline_data(data)
            
            # Atualizar estat√≠sticas
            market = data.get('market', 'unknown')
            if market in self.market_stats:
                self.market_stats[market]['messages'] += 1
                self.market_stats[market]['last_update'] = time.time()
            
            self.processed_messages += 1
            
            # Log peri√≥dico
            if self.processed_messages % 1000 == 0:
                logger.info(f"üìà Processadas {self.processed_messages:,} mensagens kline")
                
        except Exception as e:
            logger.error(f"‚ùå Erro processando kline: {e}")
            self.error_count += 1

    async def process_ticker_data(self, data: Dict[str, Any]):
        """Processar dados de ticker recebidos"""
        try:
            # Validar dados
            if not self._validate_ticker_data(data):
                return
            
            # Publicar no Redis (ticker √© mais para tempo real)
            await self.redis_publisher.publish_ticker_data(data)
            
            # Atualizar estat√≠sticas
            market = data.get('market', 'unknown')
            if market in self.market_stats:
                self.market_stats[market]['messages'] += 1
                self.market_stats[market]['last_update'] = time.time()
            
            self.processed_messages += 1
            
        except Exception as e:
            logger.error(f"‚ùå Erro processando ticker: {e}")
            self.error_count += 1

    async def process_mark_price_data(self, data: Dict[str, Any]):
        """Processar dados de mark price (futures)"""
        try:
            # Publicar no Redis
            await self.redis_publisher.publish_mark_price_data(data)
            
            # Atualizar estat√≠sticas
            market = data.get('market', 'unknown')
            if market in self.market_stats:
                self.market_stats[market]['messages'] += 1
                self.market_stats[market]['last_update'] = time.time()
            
            self.processed_messages += 1
            
        except Exception as e:
            logger.error(f"‚ùå Erro processando mark price: {e}")
            self.error_count += 1

    def _validate_kline_data(self, data: Dict[str, Any]) -> bool:
        """Validar dados de kline"""
        required_fields = [
            'symbol', 'market', 'interval', 'open_time', 'close_time',
            'open_price', 'high_price', 'low_price', 'close_price', 'volume'
        ]
        
        for field in required_fields:
            if field not in data or data[field] is None:
                logger.warning(f"‚ö†Ô∏è Campo obrigat√≥rio ausente: {field}")
                return False
        
        # Validar pre√ßos
        prices = ['open_price', 'high_price', 'low_price', 'close_price']
        for price_field in prices:
            if data[price_field] <= 0:
                logger.warning(f"‚ö†Ô∏è Pre√ßo inv√°lido {price_field}: {data[price_field]}")
                return False
        
        return True

    def _validate_ticker_data(self, data: Dict[str, Any]) -> bool:
        """Validar dados de ticker"""
        required_fields = ['symbol', 'market', 'price', 'timestamp']
        
        for field in required_fields:
            if field not in data or data[field] is None:
                return False
        
        return data['price'] > 0

    async def _monitor_system_health(self):
        """Monitorar sa√∫de do sistema"""
        while self.is_running:
            try:
                current_time = time.time()
                
                # Verificar se h√° streams ativos
                binance_status = self.binance_client.get_status()
                active_connections = binance_status.get('active_connections', 0)
                
                if active_connections == 0:
                    logger.warning("‚ö†Ô∏è Nenhum stream ativo detectado")
                else:
                    logger.info(f"‚úÖ {active_connections} streams ativos")
                
                # Atualizar status do mercado
                await self._update_market_status()
                
                self.last_health_check = current_time
                await asyncio.sleep(self.health_check_interval)
                
            except Exception as e:
                logger.error(f"‚ùå Erro no monitor de sa√∫de: {e}")
                await asyncio.sleep(10)

    async def _update_market_status(self):
        """Atualizar status dos mercados"""
        try:
            uptime = time.time() - self.start_time if self.start_time else 0
            
            logger.info(f"üìà STATS: {self.processed_messages:,} msgs, {self.error_count} erros, {uptime:.0f}s uptime")
            
            # Status por mercado
            for market, stats in self.market_stats.items():
                if stats['symbols'] > 0:
                    last_update = stats['last_update']
                    status = "üü¢" if last_update and (time.time() - last_update) < 300 else "üî¥"
                    logger.info(f"  {status} {market.upper()}: {stats['messages']:,} msgs, {stats['symbols']} s√≠mbolos")
            
        except Exception as e:
            logger.error(f"‚ùå Erro atualizando status: {e}")

    async def _periodic_cleanup(self):
        """Limpeza peri√≥dica do sistema"""
        while self.is_running:
            try:
                # Aguardar 1 hora
                await asyncio.sleep(3600)
                
                logger.info("üßπ Executando limpeza peri√≥dica...")
                
                # Limpar cache antigo
                if self.last_symbol_update and (time.time() - self.last_symbol_update) > 86400:
                    logger.info("üîÑ Atualizando cache de s√≠mbolos...")
                    await self._discover_market_symbols()
                
                # Limpar logs antigos do Redis
                await self.redis_publisher.cleanup_old_data()
                
                logger.success("‚úÖ Limpeza conclu√≠da")
                
            except Exception as e:
                logger.error(f"‚ùå Erro na limpeza: {e}")

    def get_status(self) -> Dict[str, Any]:
        """Obter status completo do sistema"""
        uptime = time.time() - self.start_time if self.start_time else 0
        
        return {
            'is_running': self.is_running,
            'uptime_seconds': uptime,
            'processed_messages': self.processed_messages,
            'error_count': self.error_count,
            'market_stats': self.market_stats,
            'binance_status': self.binance_client.get_status() if self.binance_client else {},
            'last_health_check': self.last_health_check,
            'symbols_count': {market: len(symbols) for market, symbols in self.symbols_cache.items()}
        }

    async def stop(self):
        """Parar o processador"""
        try:
            logger.info("üõë Parando Market Data Processor...")
            self.is_running = False
            
            # Parar componentes
            if self.binance_client:
                await self.binance_client.stop()
            
            if self.redis_publisher:
                await self.redis_publisher.stop()
            
            if self.postgres_manager:
                await self.postgres_manager.stop()
            
            logger.success("‚úÖ Market Data Processor parado")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao parar processor: {e}")

# Inst√¢ncia global
market_data_processor = MarketDataProcessor()
